{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ea85abf",
   "metadata": {},
   "source": [
    "## Traing and inference\n",
    "  - IV: prediction\n",
    "  - V: plotting\n",
    "  - VI: Generate the probability density and entropy data by various augmentation factors\n",
    "  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1858a9a5",
   "metadata": {},
   "source": [
    "## I. Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19b52435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged PHQ9 shape: (46, 10)\n",
      "Shape of the phq9 data with selected user is: (34, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type_x</th>\n",
       "      <th>depression severity_x</th>\n",
       "      <th>phq score_x</th>\n",
       "      <th>dp_grade_x</th>\n",
       "      <th>dp_class_x</th>\n",
       "      <th>type_y</th>\n",
       "      <th>depression severity_y</th>\n",
       "      <th>phq score_y</th>\n",
       "      <th>dp_grade_y</th>\n",
       "      <th>dp_class_y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>u00</th>\n",
       "      <td>post</td>\n",
       "      <td>minimal</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pre</td>\n",
       "      <td>minimal</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u01</th>\n",
       "      <td>post</td>\n",
       "      <td>minimal</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pre</td>\n",
       "      <td>mild</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u03</th>\n",
       "      <td>post</td>\n",
       "      <td>minimal</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pre</td>\n",
       "      <td>minimal</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u04</th>\n",
       "      <td>post</td>\n",
       "      <td>mild</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pre</td>\n",
       "      <td>mild</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u05</th>\n",
       "      <td>post</td>\n",
       "      <td>minimal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pre</td>\n",
       "      <td>minimal</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u07</th>\n",
       "      <td>post</td>\n",
       "      <td>mild</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pre</td>\n",
       "      <td>mild</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u09</th>\n",
       "      <td>post</td>\n",
       "      <td>minimal</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pre</td>\n",
       "      <td>minimal</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u10</th>\n",
       "      <td>post</td>\n",
       "      <td>minimal</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pre</td>\n",
       "      <td>minimal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u14</th>\n",
       "      <td>post</td>\n",
       "      <td>minimal</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pre</td>\n",
       "      <td>minimal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u15</th>\n",
       "      <td>post</td>\n",
       "      <td>minimal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pre</td>\n",
       "      <td>minimal</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u17</th>\n",
       "      <td>post</td>\n",
       "      <td>severe</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pre</td>\n",
       "      <td>moderate</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u18</th>\n",
       "      <td>post</td>\n",
       "      <td>moderate</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pre</td>\n",
       "      <td>severe</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u19</th>\n",
       "      <td>post</td>\n",
       "      <td>minimal</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pre</td>\n",
       "      <td>mild</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u20</th>\n",
       "      <td>post</td>\n",
       "      <td>mild</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pre</td>\n",
       "      <td>mild</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u23</th>\n",
       "      <td>post</td>\n",
       "      <td>severe</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pre</td>\n",
       "      <td>moderate</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u24</th>\n",
       "      <td>post</td>\n",
       "      <td>mild</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pre</td>\n",
       "      <td>mild</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u27</th>\n",
       "      <td>post</td>\n",
       "      <td>mild</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pre</td>\n",
       "      <td>mild</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u30</th>\n",
       "      <td>post</td>\n",
       "      <td>minimal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pre</td>\n",
       "      <td>minimal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u32</th>\n",
       "      <td>post</td>\n",
       "      <td>minimal</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pre</td>\n",
       "      <td>minimal</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u33</th>\n",
       "      <td>post</td>\n",
       "      <td>severe</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pre</td>\n",
       "      <td>severe</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u34</th>\n",
       "      <td>post</td>\n",
       "      <td>mild</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pre</td>\n",
       "      <td>minimal</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u35</th>\n",
       "      <td>post</td>\n",
       "      <td>mild</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pre</td>\n",
       "      <td>mild</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u36</th>\n",
       "      <td>post</td>\n",
       "      <td>minimal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pre</td>\n",
       "      <td>minimal</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u42</th>\n",
       "      <td>post</td>\n",
       "      <td>minimal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pre</td>\n",
       "      <td>minimal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u43</th>\n",
       "      <td>post</td>\n",
       "      <td>minimal</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pre</td>\n",
       "      <td>mild</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u44</th>\n",
       "      <td>post</td>\n",
       "      <td>minimal</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pre</td>\n",
       "      <td>minimal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u45</th>\n",
       "      <td>post</td>\n",
       "      <td>minimal</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pre</td>\n",
       "      <td>mild</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u47</th>\n",
       "      <td>post</td>\n",
       "      <td>minimal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pre</td>\n",
       "      <td>mild</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u49</th>\n",
       "      <td>post</td>\n",
       "      <td>mild</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pre</td>\n",
       "      <td>minimal</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u51</th>\n",
       "      <td>post</td>\n",
       "      <td>minimal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pre</td>\n",
       "      <td>minimal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u52</th>\n",
       "      <td>post</td>\n",
       "      <td>severe</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pre</td>\n",
       "      <td>moderate</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u56</th>\n",
       "      <td>post</td>\n",
       "      <td>minimal</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pre</td>\n",
       "      <td>minimal</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u58</th>\n",
       "      <td>post</td>\n",
       "      <td>mild</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pre</td>\n",
       "      <td>mild</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u59</th>\n",
       "      <td>post</td>\n",
       "      <td>mild</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pre</td>\n",
       "      <td>mild</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     type_x depression severity_x  phq score_x  dp_grade_x  dp_class_x type_y  \\\n",
       "user                                                                            \n",
       "u00    post               minimal          3.0         0.0         0.0    pre   \n",
       "u01    post               minimal          4.0         0.0         0.0    pre   \n",
       "u03    post               minimal          4.0         0.0         0.0    pre   \n",
       "u04    post                  mild          8.0         1.0         0.0    pre   \n",
       "u05    post               minimal          0.0         0.0         0.0    pre   \n",
       "u07    post                  mild          8.0         1.0         0.0    pre   \n",
       "u09    post               minimal          2.0         0.0         0.0    pre   \n",
       "u10    post               minimal          4.0         0.0         0.0    pre   \n",
       "u14    post               minimal          3.0         0.0         0.0    pre   \n",
       "u15    post               minimal          1.0         0.0         0.0    pre   \n",
       "u17    post                severe         18.0         3.0         1.0    pre   \n",
       "u18    post              moderate         12.0         2.0         1.0    pre   \n",
       "u19    post               minimal          4.0         0.0         0.0    pre   \n",
       "u20    post                  mild          8.0         1.0         0.0    pre   \n",
       "u23    post                severe         21.0         3.0         1.0    pre   \n",
       "u24    post                  mild          7.0         1.0         0.0    pre   \n",
       "u27    post                  mild          7.0         1.0         0.0    pre   \n",
       "u30    post               minimal          0.0         0.0         0.0    pre   \n",
       "u32    post               minimal          2.0         0.0         0.0    pre   \n",
       "u33    post                severe         25.0         3.0         1.0    pre   \n",
       "u34    post                  mild          6.0         1.0         0.0    pre   \n",
       "u35    post                  mild          7.0         1.0         0.0    pre   \n",
       "u36    post               minimal          1.0         0.0         0.0    pre   \n",
       "u42    post               minimal          0.0         0.0         0.0    pre   \n",
       "u43    post               minimal          4.0         0.0         0.0    pre   \n",
       "u44    post               minimal          2.0         0.0         0.0    pre   \n",
       "u45    post               minimal          2.0         0.0         0.0    pre   \n",
       "u47    post               minimal          1.0         0.0         0.0    pre   \n",
       "u49    post                  mild          8.0         1.0         0.0    pre   \n",
       "u51    post               minimal          0.0         0.0         0.0    pre   \n",
       "u52    post                severe         15.0         3.0         1.0    pre   \n",
       "u56    post               minimal          3.0         0.0         0.0    pre   \n",
       "u58    post                  mild          8.0         1.0         0.0    pre   \n",
       "u59    post                  mild          7.0         1.0         0.0    pre   \n",
       "\n",
       "     depression severity_y  phq score_y  dp_grade_y  dp_class_y  \n",
       "user                                                             \n",
       "u00                minimal          2.0         0.0         0.0  \n",
       "u01                   mild          5.0         1.0         0.0  \n",
       "u03                minimal          2.0         0.0         0.0  \n",
       "u04                   mild          6.0         1.0         0.0  \n",
       "u05                minimal          2.0         0.0         0.0  \n",
       "u07                   mild          7.0         1.0         0.0  \n",
       "u09                minimal          4.0         0.0         0.0  \n",
       "u10                minimal          0.0         0.0         0.0  \n",
       "u14                minimal          1.0         0.0         0.0  \n",
       "u15                minimal          3.0         0.0         0.0  \n",
       "u17               moderate         13.0         2.0         1.0  \n",
       "u18                 severe         15.0         3.0         1.0  \n",
       "u19                   mild          5.0         1.0         0.0  \n",
       "u20                   mild          8.0         1.0         0.0  \n",
       "u23               moderate         11.0         2.0         1.0  \n",
       "u24                   mild          5.0         1.0         0.0  \n",
       "u27                   mild          5.0         1.0         0.0  \n",
       "u30                minimal          1.0         0.0         0.0  \n",
       "u32                minimal          4.0         0.0         0.0  \n",
       "u33                 severe         23.0         3.0         1.0  \n",
       "u34                minimal          3.0         0.0         0.0  \n",
       "u35                   mild          7.0         1.0         0.0  \n",
       "u36                minimal          2.0         0.0         0.0  \n",
       "u42                minimal          1.0         0.0         0.0  \n",
       "u43                   mild          7.0         1.0         0.0  \n",
       "u44                minimal          1.0         0.0         0.0  \n",
       "u45                   mild          7.0         1.0         0.0  \n",
       "u47                   mild          5.0         1.0         0.0  \n",
       "u49                minimal          2.0         0.0         0.0  \n",
       "u51                minimal          1.0         0.0         0.0  \n",
       "u52               moderate         12.0         2.0         1.0  \n",
       "u56                minimal          2.0         0.0         0.0  \n",
       "u58                   mild          5.0         1.0         0.0  \n",
       "u59                   mild          5.0         1.0         0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##########  0. phq dataset #######################\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "\n",
    "dir_data = '../data/'\n",
    "\n",
    "phq = pd.read_csv(dir_data+ 'phq9_score.csv')\n",
    "# phq = phq.loc[phq['type']=='post']\n",
    "\n",
    "phq_temp=(phq.loc[:,['uid','type','depression severity','phq score','dp_grade']]).set_index('uid')\n",
    "phq_temp.rename_axis('user', inplace=True)\n",
    "\n",
    "# add phq_class column with phq_score\n",
    "dp_dict={0:0,1:0,2:1,3:1}  # grade to class\n",
    "dp_class = []\n",
    "for i in range(phq_temp.shape[0]): \n",
    "#     print(i)\n",
    "    dp_class.append(dp_dict[phq_temp[\"dp_grade\"][i]])\n",
    "phq_temp['dp_class']=dp_class  # add the class list to phq_temp dataset\n",
    "phq_temp\n",
    "\n",
    "phq_pre=phq_temp.loc[phq_temp['type']=='pre']\n",
    "phq_post=phq_temp.loc[phq_temp['type']=='post']\n",
    "phq_score= phq_post.merge(phq_pre, how='outer', left_index=True, right_index=True) # only select users whose the post-class is the same as the pre-class\n",
    "print('Merged PHQ9 shape:',phq_score.shape)\n",
    "phq_score\n",
    "\n",
    "phq_selected= phq_score.where(phq_score['dp_class_x']==phq_score['dp_class_y'])\n",
    "phq_selected.dropna(inplace=True)\n",
    "print(\"Shape of the phq9 data with selected user is:\", phq_selected.shape)\n",
    "phq_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b948c69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# DO NOT RUN THIS BLOCK !!\n",
    "\n",
    "# Another option is to use all user holds post evaluation, no matter if pre-class is the same as the post-claee\n",
    "# as blow code\n",
    "# '''\n",
    "\n",
    "# ##########  0. import phq/label and ema/sensing data #######################\n",
    "# ## select user with 'post' score available \n",
    "\n",
    "# phq = pd.read_csv(dir_data+ 'phq9_score.csv')  # shape of 84,15\n",
    "# phq = phq.loc[phq['type']=='post']\n",
    "# phq=(phq.loc[:,['uid','type','depression severity','phq score','dp_grade', 'dp_class']]).set_index('uid')\n",
    "# phq.rename_axis('user', inplace=True)  # change index from 'uid' to 'user'\n",
    "\n",
    "# print(\"PHQ-9 shape, with selected user (post): \", phq.shape)\n",
    "\n",
    "# ## import EMA/sensing data\n",
    "# dataset = pd.read_csv(dir_data+'studentlife_data_full.csv', index_col=0)#set the col0 as index, index as \"u00_2013-03-24\"\n",
    "\n",
    "# print ('Dataset shape :',dataset.shape)\n",
    "# # dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79252c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Dataset_ema shape:  (3025, 107)\n",
      "2. Dataset_sensing shape:  (3075, 12)\n",
      "3. Merge success ! shape of merged dataset is (3407, 119)\n",
      "\n",
      "a. Removed columns of non-data, EMA dataset shape:  (3025, 81)\n",
      "b. Removed columns of non-data, sensing dataset shape:  (3075, 6)\n",
      "c. Removed columns of non-data, merged dataset shape:  (3407, 78)\n",
      "Full dataset saved in: ../data/\n"
     ]
    }
   ],
   "source": [
    "#################  1 merge sensing and ema  ####################\n",
    "######### ema_all.csv, sensing_all.csv  ###################\n",
    "dataset_ema = pd.read_csv(dir_data+ 'ema_all.csv', index_col=0)  \n",
    "print ('1. Dataset_ema shape: ',dataset_ema.shape)\n",
    "\n",
    "dataset_sensing = pd.read_csv(dir_data+ 'sensing_all.csv', index_col=0)  \n",
    "print ('2. Dataset_sensing shape: ',dataset_sensing.shape)\n",
    "\n",
    "######### clean data ###########\n",
    "dataset= dataset_sensing.merge(dataset_ema, how='outer', left_index=True, right_index=True )\n",
    "print('3. Merge success ! shape of merged dataset is', dataset.shape )\n",
    "\n",
    "def drop_notnum(dataset):\n",
    "    cols=dataset.columns\n",
    "    col_notnum=[]\n",
    "    for col in cols:\n",
    "        if str(dataset[col].dtype)=='object':\n",
    "               col_notnum.append(col)\n",
    "    dataset=dataset.drop(col_notnum, axis=1)\n",
    "    return dataset\n",
    "\n",
    "dataset=drop_notnum(dataset)  #abc=dataset.dropna(axis=1, how='all') # drops columns those with all NaN\n",
    "dataset_ema= drop_notnum(dataset_ema)\n",
    "dataset_sensing = drop_notnum(dataset_sensing)\n",
    "\n",
    "# drop of feature contains all null values\n",
    "null_feature = ['Class_null',\n",
    " 'Stress_null',\n",
    " 'Mood 2_null',\n",
    " 'Behavior_null',\n",
    " 'Study Spaces_null',\n",
    " 'Sleep_null',\n",
    " 'Activity_null',\n",
    " 'Social_null',\n",
    " 'Green Key 2_excited']\n",
    "dataset = dataset.drop(null_feature, axis =1)\n",
    "\n",
    "print('')\n",
    "print('a. Removed columns of non-data, EMA dataset shape: ', dataset_ema.shape)\n",
    "print('b. Removed columns of non-data, sensing dataset shape: ', dataset_sensing.shape)\n",
    "print('c. Removed columns of non-data, merged dataset shape: ', dataset.shape)\n",
    "\n",
    "# dataset.to_csv(os.path.join(dir_data+\"studentlife_datafull.csv\"))\n",
    "print('Full dataset saved in:', dir_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbc3580",
   "metadata": {},
   "source": [
    "## II. Build model and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94d50596",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## 2. build base model and function ##########################\n",
    "from abc import ABC, abstractmethod\n",
    "from keras.models import Sequential\n",
    "# from keras import backend as K\n",
    "# from keras import Input\n",
    "# from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "from keras.layers import Embedding, Dense, Dropout, BatchNormalization,LeakyReLU, MaxPooling2D, Conv2D,Flatten\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support,  accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# from matplotlib import dates as mdates\n",
    "\n",
    "\n",
    "class BaseModel(ABC):\n",
    "    \"\"\" Super class for Machine Learning Class\"\"\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def train_predict(self):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def predict(self):\n",
    "        pass\n",
    "        \n",
    "    def load_predict(self, X, predict_type):\n",
    "        pass\n",
    "    \n",
    "    def accuracy(self, predict, label):\n",
    "        predict = predict.ravel()\n",
    "        label = label.ravel()\n",
    "        return np.sum(predict == label)/len(label) \n",
    "\n",
    "def accuracy(predict, label):\n",
    "    predict = predict.ravel()\n",
    "    label = label.ravel()\n",
    "    return np.sum(predict == label)/len(label) \n",
    "\n",
    "# def dataExtract(data, win_width =10, stride =1, forward_step= 0, label = 'label', normalize = False): # output 3 dimensions array\n",
    "#     sample_num = data.shape[0]\n",
    "\n",
    "#     y=data.loc[:,label].values\n",
    "#     X = data.drop(columns = [label]) # drop 'label column, use remain for feature\n",
    "#     feature_num = X.shape[1]\n",
    "#     if normalize == True:\n",
    "#         X = minmaxNormalize(X)\n",
    "# #         X = Normalize(X)\n",
    "#     X_new = np.array([[]]*feature_num).T.reshape(0,win_width,feature_num) # 3D empty array\n",
    "#     y_new = []\n",
    "#     for i in range(sample_num-forward_step,0, -stride):\n",
    "#         X_win = X.values[i-win_width:i,:] \n",
    "#         if X_win.shape[0] <win_width:\n",
    "#             break \n",
    "#         X_win = X_win.reshape(1,win_width,feature_num) # reshape to 3D for catanecating\n",
    "#         X_new = np.vstack((X_new,X_win)) \n",
    "#         y_new.append(y[i+forward_step-1]) \n",
    "#     X_new = X_new[::-1,:,:] \n",
    "#     y_new = np.array(y_new[::-1]) \n",
    "#     return X_new, y_new # retrun array instead of dataframe\n",
    "\n",
    "def minmaxNormalize(X, axis = 0): # default axis set to 0\n",
    "    minum = np.min(X, axis = axis)\n",
    "    maxum = np.max(X, axis = axis)\n",
    "    return (X-minum)/(maxum-minum)\n",
    "\n",
    "def Normalize(X):\n",
    "    return  X/np.linalg.norm(X, ord = 2, axis = 0)\n",
    "\n",
    "def PCA(X, k, axis=1):  # feature in rows axis =0, in cols axis =1, X in np.array formate\n",
    "    if axis==0:  #features by rows\n",
    "        n = X.shape[0]\n",
    "        mean = np.mean(X, axis = 0).reshape(1,-1) # features number X data number \n",
    "        Xm = (X- mean)\n",
    "        COV =  Xm @ Xm.T/(n-1)\n",
    "        eig_value, eig_vector = np.linalg.eig(COV) \n",
    "        index = np.argsort(-1*eig_value) # rank from the largest value to the smallest one， descend\n",
    "        P = eig_vector[:,index[0:k]]\n",
    "        return P.T @ Xm\n",
    "    else:  #axis == 1, features by cols\n",
    "#         X=dataframe.values\n",
    "        n = np.array(X).shape[1]\n",
    "        mean = np.mean(X, axis = 1).reshape(-1,1) # features number X data number \n",
    "        Xm = (X- mean)\n",
    "        COV =  Xm.T@Xm/(n-1)\n",
    "        eig_value, eig_vector = np.linalg.eig(COV) \n",
    "        index = np.argsort(-1*eig_value) # rank from the largest value to the smallest one， descend\n",
    "        P = eig_vector[:,index[0:k]]\n",
    "        return Xm@P\n",
    "    \n",
    "\n",
    "def slice_sum_by_id(data,id_list, win_width, stride, forward_step, label):\n",
    "    x_f=np.array([])\n",
    "    y_f=np.array([])\n",
    "#     id_list =np.unique(data['ID'])\n",
    "    for id in id_list:\n",
    "        #data_id= (data.where(data['ID']==id)).dropna()\n",
    "        data_id= data[data.index==id]\n",
    "        x_sliced, y_sliced = dataExtract(data_id, win_width =win_width, stride =stride, \\\n",
    "                                         forward_step= forward_step, label = label, normalize = False)\n",
    "        if not x_f.any():  # initialize 3d array\n",
    "            x_f=np.empty(shape=x_sliced.shape)  #sliced size for each id =90-(win_width+stride+forward_step)+2\n",
    "            y_f=np.empty(shape=y_sliced.shape)\n",
    "            init=x_sliced.shape[0]\n",
    "        x_f= np.append(x_f,x_sliced, axis=0)\n",
    "        y_f= np.append(y_f,y_sliced, axis=0)\n",
    "    x_f=x_f[init:,:,:]  # take off the first chunk created by np.empty : size of init\n",
    "    y_f=y_f[init:,]\n",
    "    return x_f, y_f\n",
    "\n",
    "''' create a diction of score:grade '''\n",
    "dp_grade ={0:[0,4], 1:[5,9],2:[10,14],3:[15,19],4:[20,27]} \n",
    "dp_score2grade={}\n",
    "for key, value in dp_grade.items(): \n",
    "    for i in range(value[0], value[1]+1):\n",
    "        dp_score2grade[i]=key\n",
    "        \n",
    "# normalize dataset and fill nan with -1\n",
    "def minmax_normalize(df): # this min_max norm can apply dataset with NULL value\n",
    "    for col in df.columns:\n",
    "        df[col]= (df[col]-df[col].min())/(df[col].max()-df[col].min())\n",
    "#     df.dropna(how='any', inplace=True, axis=1) # drop columns with null falue\n",
    "    return df\n",
    "\n",
    "def normalize_list(la): # normalize a 1 dimension list\n",
    "    if sum(la)==0:\n",
    "        lb =la # doesn't consider all la element =0\n",
    "    else:\n",
    "        lb=[]\n",
    "        [lb.append(v/sum(la)) for v in la]  \n",
    "    return lb\n",
    "\n",
    "def entropy(lst):\n",
    "    result= 0;\n",
    "    lst = normalize_list(lst)\n",
    "    for p in lst:\n",
    "        if p == 0:\n",
    "            pass\n",
    "        else:\n",
    "            result+=(-p)*np.log2(p)\n",
    "    return result\n",
    "\n",
    "def classifier_slice2uid(df_predicted, trigger=0.1): # 2nd round classification by user catogory in trigger method, binary\n",
    "    users= np.unique(df_predicted.index)\n",
    "    score_user ={}\n",
    "    class_user ={}\n",
    "    for user in users:\n",
    "        class_slice = df_predicted.loc[user][0].to_list()\n",
    "        score= sum(class_slice)/len(class_slice)\n",
    "        score_user[user]=score\n",
    "    for user, score in score_user.items():\n",
    "        class_user[user]= int(score-trigger+1) # convert the value >threshold to be 1 \n",
    "    predictions_user = pd.DataFrame(class_user.values(), index = class_user.keys()) # transfer diction to dataframe\n",
    "    return predictions_user , score_user\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acabe61",
   "metadata": {},
   "source": [
    "## III. data cleaning and train/test data processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84971088",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 0. pick up features\n",
    "'''\n",
    "\n",
    "\n",
    "# 0. all features\n",
    "col_slct= dataset.columns # ALL features, 78 cols after manully filter \"null\" and \"green\" columns\n",
    "\n",
    "# # 1. EMA 6 + sensing 4\n",
    "col_slct=['Mood_happyornot','PAM_picture_idx', 'Mood_sad','Stress_level','Sleep_social','Sleep_rate',\n",
    "            'dark_duration(sec)','audio_ audio inference',\n",
    "            'phonecharge_duration(sec)','activity_ activity inference'] \n",
    "\n",
    "# # 2. EMA  6 features\n",
    "col_slct=['Mood_happyornot','PAM_picture_idx', 'Mood_sad','Stress_level','Sleep_social','Sleep_rate']\n",
    "\n",
    "# # # # 3. sensing 4 features\n",
    "col_slct=['dark_duration(sec)','audio_ audio inference',\n",
    "          'phonecharge_duration(sec)','activity_ activity inference'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95b4a43e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''1. Data cleaning:\n",
    "    - select columns\n",
    "    - normalization, or\n",
    "    - PCA (on demand)\n",
    "'''\n",
    "## normalization\n",
    "dataset_col = dataset[col_slct].copy()\n",
    "data_norm= minmax_normalize(dataset_col)\n",
    "\n",
    "\n",
    "## process PCA ############\n",
    "# dataset_np = data_norm.iloc[:,1:].to_numpy()  # transfer to numpy without index of 'user_date'\n",
    "# K=2\n",
    "# dataset_np=PCA(dataset_np, K, axis= 1)\n",
    "# dataset_np.shape\n",
    "# dataset_pca=pd.DataFrame(dataset_np, columns= np.arange(K), index= data_norm.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91da02b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset before labeling is: (3407, 4)\n",
      "After labeling and removing non-completed label, dataset shape is: (2405, 5)\n"
     ]
    }
   ],
   "source": [
    "''' 2. Data cleaning:\n",
    "    - index: user_date to user\n",
    "    - add lables\n",
    "    - clean data\n",
    "    '''\n",
    "########### 1.2 add label(dp_class) by merging phq ###############\n",
    "########## add uer and set as index for merging phq ###########\n",
    "\n",
    "\n",
    "# dataset_1=dataset   # no pca, no normalization\n",
    "# dataset_1= dataset_pca # with both normalization + pca\n",
    "dataset_1 = data_norm # with normalization , no pca\n",
    "\n",
    "dataset_1['user']=dataset_1.index  # copy 'user' column with index values\n",
    "def str_slice(str):\n",
    "    return str[:3]\n",
    "dataset_1['user']=dataset_1['user'].apply(str_slice)\n",
    "dataset_1 = dataset_1.reset_index().set_index('user') \n",
    "dataset_1 = dataset_1.drop(['user_date'], axis=1)# keep the index columns and set 'user' col as index\n",
    "dataset_1.fillna(0, inplace= True)  # impute 0 into missing data\n",
    "print(\"Dataset before labeling is:\", dataset_1.shape)\n",
    "\n",
    "## add label of dp_class\n",
    "dp_class_list=[]\n",
    "for user in dataset_1.index: \n",
    "    if user in phq_selected.index.to_list():\n",
    "        dp_class_list.append(phq_selected.loc[user]['dp_class_y'])\n",
    "    else:\n",
    "        dp_class_list.append(None) # for removing those users are not in the selected list\n",
    "dataset_1['dp_class']=dp_class_list\n",
    "\n",
    "dataset_1= dataset_1.dropna(axis = 0, how='any') # drop off instance without lable (non-selected user)  \n",
    "\n",
    "dataset_1.to_csv(dir_data+\"studentlife_datafull_with_lable.csv\")\n",
    "\n",
    "# dataset_2 = minmax_normalize(dataset_1)\n",
    "print(\"After labeling and removing non-completed label, dataset shape is:\", dataset_1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40c7968c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X train, y_train, X test, y test :  (2146, 4) (2146,) (541, 4) (541,)\n",
      "size of feature selected: 4\n"
     ]
    }
   ],
   "source": [
    "''' 3. Traing and testing dataset processing:\n",
    "    - Split training and testing dataset\n",
    "    - Data augment : pick the id with depression ,which stays in train dataset for augmenting'''\n",
    "\n",
    "################## process training and testing data #######################\n",
    "\n",
    "random_seed= 0 # 1 depression :42, 0 ,3 ; 0 depression: 2,5, 6\n",
    "trigger =0.2 # threshold for 2nd round classification\n",
    "\n",
    "\n",
    "agm_factor = 4 # for testing add 4 times depressed user data, randomly\n",
    "\n",
    "\n",
    "def generate_train_test(dataset, agm_factor=agm_factor, random_seed = random_seed):\n",
    "    random.seed(random_seed)\n",
    "    split_rate =0.8\n",
    "    \n",
    "\n",
    "    id_depression_all=list(np.unique(dataset.where(dataset_1['dp_class'] == 1).dropna().index)) # users who has depression\n",
    "    id_depression_test=[]    \n",
    "      #### for test with data version 1\n",
    "#     id_depression_all=['u17', 'u18','u23','u33','u52'] # users who have depression\n",
    "#     ####\n",
    "    \n",
    "    id_list =list(np.unique(dataset.index))\n",
    "    split = int(split_rate*len(id_list))\n",
    "    id_train= sorted(random.sample(id_list,split))\n",
    "    id_test= sorted(list(set(id_list)- set(id_train)))\n",
    "    id_depression_train=[]\n",
    "\n",
    "    for id in id_depression_all:\n",
    "        if (id in id_train):\n",
    "            id_depression_train.append(id)\n",
    "\n",
    "#     ### another way to split by make sure at least there is a depressed user in test data\n",
    "#     # id depression    \n",
    "#     id_depression_test = random.sample(id_depression_all,1)\n",
    "#     id_depression_train = list(set(id_depression_all)- set(id_depression_test))\n",
    "\n",
    "#     # id nonedepression\n",
    "#     split = round(split_rate*len(id_nonedepression_all))\n",
    "#     id_nonedepression_train= random.sample(id_nonedepression_all, split)\n",
    "#     id_nonedepression_test = list(set(id_nonedepression_all)-set(id_nonedepression_train))\n",
    "\n",
    "#     id_test = sorted(id_depression_test + id_nonedepression_test)\n",
    "#     id_train = sorted(id_depression_train + id_nonedepression_train)\n",
    "\n",
    "    id_augment = []\n",
    "    for i in range(agm_factor): # add X users with depression     \n",
    "        id_augment.append(random.sample(id_depression_train,1)[0])\n",
    "    id_agm =id_train+id_augment\n",
    "    random.shuffle(id_agm)\n",
    "\n",
    "\n",
    "    X_train= dataset.loc[id_agm,:].iloc[:,:-1] # X_train shape[0] will increase after augmenting\n",
    "    y_train= dataset.loc[id_agm,:].iloc[:,-1]\n",
    "\n",
    "    X_test= dataset.loc[id_test,:].iloc[:,:-1]\n",
    "    y_test= dataset.loc[id_test,:].iloc[:,-1]\n",
    "\n",
    "    y_train_dummy = pd.get_dummies(y_train).values\n",
    "    y_test_dummy = pd.get_dummies(y_test).values\n",
    "    \n",
    "#     print('Testing for augmentation factor:', agm_factor)\n",
    "#     print('Users in test data: ',id_test)\n",
    "#     print('Users in agmentated training data: ', id_agm)\n",
    "    \n",
    "    return X_train, y_train, X_test , y_test, y_train_dummy, y_test_dummy, id_train, id_test\n",
    "\n",
    "## split train/test  and dummy y\n",
    "X_train, y_train, X_test , y_test, y_train_dummy, y_test_dummy, id_train, id_test  = generate_train_test(dataset_1, agm_factor=agm_factor, random_seed = random_seed)\n",
    "print(\"Shape of X train, y_train, X test, y test : \",X_train.shape,  y_train.shape, X_test.shape, y_test.shape )\n",
    "print(\"size of feature selected:\", len(col_slct))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2438fb49",
   "metadata": {},
   "source": [
    "## Prediction stage-1\n",
    "    - store the result to file: dir_data+\"likelihood.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d5437b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "A. train and predict by Machine Learning algorithms\n",
    "\n",
    "'''\n",
    "from sklearn.ensemble import RandomForestClassifier #1\n",
    "from sklearn.linear_model import LogisticRegression #2\n",
    "from sklearn import tree #3\n",
    "from sklearn.ensemble import  GradientBoostingClassifier #4\n",
    "from sklearn.ensemble import  AdaBoostClassifier #5\n",
    "from sklearn.naive_bayes import GaussianNB # 6\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis # 7\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis # 8\n",
    "from sklearn.svm import SVC #9\n",
    "from sklearn.neighbors import KNeighborsClassifier # 10\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_curve, confusion_matrix\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.rcParams['font.sans-serif']=[u'simHei']\n",
    "matplotlib.rcParams['axes.unicode_minus']=False\n",
    "\n",
    "\n",
    "test_class = pd.DataFrame(id_test, columns=['uid']).merge(phq, on=['uid'], how ='inner')\n",
    "y_test_uid= test_class[['uid','dp_class']].drop_duplicates()['dp_class'].tolist()  #[0, 0, 0, 1, 0, 0, 0]  for ['u00', 'u07', 'u10', 'u17', 'u34', 'u35', 'u47']\n",
    "\n",
    "# ===========================machine learning algorithms to predict and plot====================#\n",
    "def ml_predict_score_user(X_train, y_train, X_test, y_test_uid):  \n",
    "\n",
    "    ### 1. Random Foreest\n",
    "    \n",
    "#     print(\"=============================================================================================\")      \n",
    "#     print(\"1. RF\")\n",
    "\n",
    "    RF = RandomForestClassifier(n_estimators=10,random_state=11)\n",
    "    RF.fit(X_train,y_train)\n",
    "    predictions_1 = RF.predict(X_test)\n",
    "\n",
    "    predicted_df = pd.DataFrame(predictions_1, index =X_test.index) \n",
    "    predictions_temp, likelihood_1  = classifier_slice2uid(predicted_df, trigger= trigger) \n",
    "    predictions_1 =  predictions_temp.iloc[:,-1].to_list() \n",
    "    y_test = np.array(phq_score.loc[list(predictions_temp.index),\"dp_class_y\"].to_list()) \n",
    "    mse_1 = np.sum((y_test-list(likelihood_1.values()))**2/len(y_test))\n",
    "\n",
    "#     print(likelihood_1)\n",
    "#     print(\"mse of score by users: \",mse_1)\n",
    "#     print(classification_report(y_test,predictions_1))\n",
    "#     print(\"AC\",accuracy_score(y_test,predictions_1))\n",
    "\n",
    "\n",
    "\n",
    "#     ####################### Plot ############################\n",
    "#     fpr_1, tpr_1, thresholds_1 = \\\n",
    "#     roc_curve(y_test,predictions_1)\n",
    "#     plt.figure(figsize=(10,4))\n",
    "\n",
    "#     plt.subplot(121)\n",
    "#     # plt.xlim(0,1) \n",
    "#     # plt.ylim(0.0,1.1) \n",
    "#     plt.title('ROC',fontsize=14,fontweight='bold')\n",
    "#     plt.xlabel('False Postive Rate')\n",
    "#     plt.ylabel('True Postive Rate')\n",
    "#     plt.plot(fpr_1,tpr_1,linewidth=2, linestyle=\"-\",color='red')\n",
    "\n",
    "#     plt.subplot(122)\n",
    "#     ticks=['Normal','Depression']\n",
    "#     conf_mat = confusion_matrix(y_test, predictions_1)\n",
    "#     sns.heatmap(conf_mat, annot=True, fmt='d',\n",
    "#                 xticklabels=ticks, yticklabels=ticks,cmap=\"Blues\")\n",
    "#     plt.title('Confusion Matrix',fontsize=14,fontweight='bold')\n",
    "#     plt.ylabel('Actual',fontsize=12)\n",
    "#     plt.xlabel('Prediction',fontsize=12)\n",
    "#     plt.show()\n",
    "\n",
    "    ###2. Logistic Regression Classifier \n",
    "    \n",
    "#     print(\"=============================================================================================\")      \n",
    "#     print(\"2. LR\")\n",
    "\n",
    "    clf = LogisticRegression(penalty='l2')\n",
    "    clf.fit(X_train,y_train)\n",
    "    predictions_2 = clf.predict(X_test)\n",
    "\n",
    "    predicted_df = pd.DataFrame(predictions_2, index =X_test.index) \n",
    "    predictions_temp, likelihood_2  = classifier_slice2uid(predicted_df, trigger= trigger) \n",
    "    predictions_2 =  predictions_temp.iloc[:,-1].to_list() \n",
    "    y_test = np.array(phq_score.loc[list(predictions_temp.index),\"dp_class_y\"].to_list()) \n",
    "    mse_2 = np.sum((y_test-list(likelihood_2.values()))**2/len(y_test))\n",
    "\n",
    "#     print(likelihood_2)\n",
    "#     print(\"mse of score by users: \",mse_2)\n",
    "#     print(classification_report(y_test,predictions_2))\n",
    "#     print(\"AC\",accuracy_score(y_test,predictions_2))\n",
    "\n",
    "#     ####################### Plot ############################\n",
    "#     fpr_2, tpr_2, thresholds_2 = \\\n",
    "#     roc_curve(y_test,predictions_2)\n",
    "#     plt.figure(figsize=(10,4))\n",
    "\n",
    "#     plt.subplot(121)\n",
    "#     # plt.xlim(0,1) \n",
    "#     # plt.ylim(0.0,1.1) \n",
    "#     plt.title('ROC',fontsize=14,fontweight='bold')\n",
    "#     plt.xlabel('False Postive Rate')\n",
    "#     plt.ylabel('True Postive Rate')\n",
    "#     plt.plot(fpr_2,tpr_2,linewidth=2, linestyle=\"-\",color='red')\n",
    "\n",
    "#     plt.subplot(122)\n",
    "#     ticks=['Normal','Depression']\n",
    "#     conf_mat = confusion_matrix(y_test, predictions_2)\n",
    "#     sns.heatmap(conf_mat, annot=True, fmt='d',\n",
    "#                 xticklabels=ticks, yticklabels=ticks,cmap=\"Blues\")\n",
    "#     plt.title('Confusion Matrix',fontsize=14,fontweight='bold')\n",
    "#     plt.ylabel('Actual',fontsize=12)\n",
    "#     plt.xlabel('Prediction',fontsize=12)\n",
    "#     plt.show()\n",
    "\n",
    "    ### 3. Decision Tree Classifier    \n",
    "#     print(\"=============================================================================================\")    \n",
    "#     print(\"3. Decision Tree\")\n",
    "\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf.fit(X_train,y_train)\n",
    "    predictions_3 = clf.predict(X_test)\n",
    "\n",
    "\n",
    "    predicted_df = pd.DataFrame(predictions_3, index =X_test.index) \n",
    "    predictions_temp, likelihood_3  = classifier_slice2uid(predicted_df, trigger= trigger) \n",
    "    predictions_3 =  predictions_temp.iloc[:,-1].to_list() \n",
    "    y_test = np.array(phq_score.loc[list(predictions_temp.index),\"dp_class_y\"].to_list()) \n",
    "    mse_3 = np.sum((y_test-list(likelihood_3.values()))**2/len(y_test))\n",
    "\n",
    "#     print(likelihood_3)\n",
    "#     print(\"mse of score by users: \",mse_3)\n",
    "#     print(classification_report(y_test,predictions_3))\n",
    "#     print(\"AC\",accuracy_score(y_test,predictions_3))\n",
    "\n",
    "#     ####################### Plot ############################\n",
    "#     fpr_3, tpr_3, thresholds_3 = \\\n",
    "#     roc_curve(y_test,predictions_3)\n",
    "#     plt.figure(figsize=(10,4))\n",
    "\n",
    "#     plt.subplot(121)\n",
    "#     # plt.xlim(0,1) \n",
    "#     # plt.ylim(0.0,1.1) \n",
    "#     plt.title('ROC',fontsize=14,fontweight='bold')\n",
    "#     plt.xlabel('False Postive Rate')\n",
    "#     plt.ylabel('True Postive Rate')\n",
    "#     plt.plot(fpr_3,tpr_3,linewidth=2, linestyle=\"-\",color='red')\n",
    "\n",
    "#     plt.subplot(122)\n",
    "#     ticks=['Normal','Depression']\n",
    "#     conf_mat = confusion_matrix(y_test, predictions_3)\n",
    "#     sns.heatmap(conf_mat, annot=True, fmt='d',\n",
    "#                 xticklabels=ticks, yticklabels=ticks,cmap=\"Blues\")\n",
    "#     plt.title('Confusion Matrix',fontsize=14,fontweight='bold')\n",
    "#     plt.ylabel('Actual',fontsize=12)\n",
    "#     plt.xlabel('Prediction',fontsize=12)\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "    ###4. Gradient Boosting Decision Tree\n",
    "#     print(\"=============================================================================================\")\n",
    "#     print(\"4. Gradient Boosting Decision Tree\")    \n",
    "    clf = GradientBoostingClassifier()\n",
    "    clf.fit(X_train,y_train)\n",
    "    predictions_4 = clf.predict(X_test)\n",
    "\n",
    "    predicted_df = pd.DataFrame(predictions_4, index =X_test.index) \n",
    "    predictions_temp, likelihood_4  = classifier_slice2uid(predicted_df, trigger= trigger) \n",
    "    predictions_4 =  predictions_temp.iloc[:,-1].to_list() \n",
    "    y_test = np.array(phq_score.loc[list(predictions_temp.index),\"dp_class_y\"].to_list()) \n",
    "    mse_4 = np.sum((y_test-list(likelihood_4.values()))**2/len(y_test))\n",
    "\n",
    "#     print(likelihood_4)\n",
    "#     print(\"mse of score by users: \",mse_4)\n",
    "#     print(classification_report(y_test,predictions_4))\n",
    "#     print(\"AC\",accuracy_score(y_test,predictions_4))\n",
    "\n",
    "#     ####################### Plot ############################\n",
    "#     fpr_4, tpr_4, thresholds_4 = \\\n",
    "#     roc_curve(y_test,predictions_4)\n",
    "#     plt.figure(figsize=(10,4))\n",
    "\n",
    "#     plt.subplot(121)\n",
    "#     # plt.xlim(0,1) \n",
    "#     # plt.ylim(0.0,1.1) \n",
    "#     plt.title('ROC',fontsize=14,fontweight='bold')\n",
    "#     plt.xlabel('False Postive Rate')\n",
    "#     plt.ylabel('True Postive Rate')\n",
    "#     plt.plot(fpr_4,tpr_4,linewidth=2, linestyle=\"-\",color='red')\n",
    "\n",
    "#     plt.subplot(122)\n",
    "#     ticks=['Normal','Depression']\n",
    "#     conf_mat = confusion_matrix(y_test, predictions_4)\n",
    "#     sns.heatmap(conf_mat, annot=True, fmt='d',\n",
    "#                 xticklabels=ticks, yticklabels=ticks,cmap=\"Blues\")\n",
    "#     plt.title('Confusion Matrix',fontsize=14,fontweight='bold')\n",
    "#     plt.ylabel('Actual',fontsize=12)\n",
    "#     plt.xlabel('Prediction',fontsize=12)\n",
    "#     plt.show()\n",
    "\n",
    "    ###5. AdaBoost Classifier\n",
    "#     print(\"=============================================================================================\")     \n",
    "#     print(\"5. AdaBoost\")\n",
    "\n",
    "    clf = AdaBoostClassifier()\n",
    "    clf.fit(X_train,y_train)\n",
    "    predictions_5 = clf.predict(X_test)\n",
    "\n",
    "    predicted_df = pd.DataFrame(predictions_5, index =X_test.index) \n",
    "    predictions_temp, likelihood_5  = classifier_slice2uid(predicted_df, trigger= trigger) \n",
    "    predictions_5 =  predictions_temp.iloc[:,-1].to_list() \n",
    "    y_test = np.array(phq_score.loc[list(predictions_temp.index),\"dp_class_y\"].to_list()) \n",
    "    mse_5 = np.sum((y_test-list(likelihood_5.values()))**2/len(y_test))\n",
    "\n",
    "#     print(likelihood_5)\n",
    "#     print(\"mse of score by users: \",mse_5)\n",
    "#     print(classification_report(y_test,predictions_5))\n",
    "#     print(\"AC\",accuracy_score(y_test,predictions_5))\n",
    "\n",
    "#     ####################### Plot ############################\n",
    "#     fpr_5, tpr_5, thresholds_5 = \\\n",
    "#     roc_curve(y_test,predictions_5)\n",
    "#     plt.figure(figsize=(10,4))\n",
    "\n",
    "#     plt.subplot(121)\n",
    "#     # plt.xlim(0,1) \n",
    "#     # plt.ylim(0.0,1.1) \n",
    "#     plt.title('ROC',fontsize=14,fontweight='bold')\n",
    "#     plt.xlabel('False Postive Rate')\n",
    "#     plt.ylabel('True Postive Rate')\n",
    "#     plt.plot(fpr_5,tpr_5,linewidth=2, linestyle=\"-\",color='red')\n",
    "\n",
    "#     plt.subplot(122)\n",
    "#     ticks=['Normal','Depression']\n",
    "#     conf_mat = confusion_matrix(y_test, predictions_5)\n",
    "#     sns.heatmap(conf_mat, annot=True, fmt='d',\n",
    "#                 xticklabels=ticks, yticklabels=ticks,cmap=\"Blues\")\n",
    "#     plt.title('Confusion Matrix',fontsize=14,fontweight='bold')\n",
    "#     plt.ylabel('Actual',fontsize=12)\n",
    "#     plt.xlabel('Prediction',fontsize=12)\n",
    "#     plt.show()\n",
    "\n",
    "    ### 6. GaussianNB\n",
    "#     print(\"=============================================================================================\")     \n",
    "#     print(\"6. GaussianNB\")\n",
    "\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(X_train,y_train)\n",
    "    predictions_6 = clf.predict(X_test)\n",
    "\n",
    "    predicted_df = pd.DataFrame(predictions_6, index =X_test.index) \n",
    "    predictions_temp, likelihood_6  = classifier_slice2uid(predicted_df, trigger= trigger) \n",
    "    predictions_6 =  predictions_temp.iloc[:,-1].to_list() \n",
    "    y_test = np.array(phq_score.loc[list(predictions_temp.index),\"dp_class_y\"].to_list()) \n",
    "    mse_6 = np.sum((y_test-list(likelihood_6.values()))**2/len(y_test))\n",
    "\n",
    "#     print(likelihood_6)\n",
    "#     print(\"mse of score by users: \",mse_6)\n",
    "#     print(classification_report(y_test,predictions_6))\n",
    "#     print(\"AC\",accuracy_score(y_test,predictions_6))\n",
    "\n",
    "#     ####################### Plot ############################\n",
    "#     fpr_6, tpr_6, thresholds_6 = \\\n",
    "#     roc_curve(y_test,predictions_6)\n",
    "#     plt.figure(figsize=(10,4))\n",
    "\n",
    "#     plt.subplot(121)\n",
    "#     # plt.xlim(0,1) \n",
    "#     # plt.ylim(0.0,1.1) \n",
    "#     plt.title('ROC',fontsize=14,fontweight='bold')\n",
    "#     plt.xlabel('False Postive Rate')\n",
    "#     plt.ylabel('True Postive Rate')\n",
    "#     plt.plot(fpr_6,tpr_6,linewidth=2, linestyle=\"-\",color='red')\n",
    "\n",
    "#     plt.subplot(122)\n",
    "#     ticks=['Normal','Depression']\n",
    "#     conf_mat = confusion_matrix(y_test, predictions_6)\n",
    "#     sns.heatmap(conf_mat, annot=True, fmt='d',\n",
    "#                 xticklabels=ticks, yticklabels=ticks,cmap=\"Blues\")\n",
    "#     plt.title('Confusion Matrix',fontsize=14,fontweight='bold')\n",
    "#     plt.ylabel('Actual',fontsize=12)\n",
    "#     plt.xlabel('Prediction',fontsize=12)\n",
    "#     plt.show()\n",
    "\n",
    "    ### 7. Linear Discriminant Analysis\n",
    "#     print(\"=============================================================================================\")  \n",
    "#     print(\"7. Linear Discriminant Analysis\")\n",
    "\n",
    "    clf = LinearDiscriminantAnalysis()\n",
    "    clf.fit(X_train,y_train)\n",
    "    predictions_7 = clf.predict(X_test)\n",
    "\n",
    "    predicted_df = pd.DataFrame(predictions_7, index =X_test.index) \n",
    "    predictions_temp, likelihood_7  = classifier_slice2uid(predicted_df, trigger= trigger) \n",
    "    predictions_7 =  predictions_temp.iloc[:,-1].to_list() \n",
    "    y_test = np.array(phq_score.loc[list(predictions_temp.index),\"dp_class_y\"].to_list()) \n",
    "    mse_7 = np.sum((y_test-list(likelihood_7.values()))**2/len(y_test))\n",
    "\n",
    "#     print(likelihood_7)\n",
    "#     print(\"mse of score by users: \",mse_7)\n",
    "#     print(classification_report(y_test,predictions_7))\n",
    "#     print(\"AC\",accuracy_score(y_test,predictions_7))\n",
    "\n",
    "#     ####################### Plot ############################\n",
    "#     fpr_7, tpr_7, thresholds = \\\n",
    "#     roc_curve(y_test,predictions_7)\n",
    "#     plt.figure(figsize=(10,4))\n",
    "\n",
    "#     plt.subplot(121)\n",
    "#     # plt.xlim(0,1) \n",
    "#     # plt.ylim(0.0,1.1) \n",
    "#     plt.title('ROC',fontsize=14,fontweight='bold')\n",
    "#     plt.xlabel('False Postive Rate')\n",
    "#     plt.ylabel('True Postive Rate')\n",
    "#     plt.plot(fpr_7,tpr_7,linewidth=2, linestyle=\"-\",color='red')\n",
    "\n",
    "#     plt.subplot(122)\n",
    "#     ticks=['Normal','Depression']\n",
    "#     conf_mat = confusion_matrix(y_test, predictions_7)\n",
    "#     sns.heatmap(conf_mat, annot=True, fmt='d',\n",
    "#                 xticklabels=ticks, yticklabels=ticks,cmap=\"Blues\")\n",
    "#     plt.title('Confusion Matrix',fontsize=14,fontweight='bold')\n",
    "#     plt.ylabel('Actual',fontsize=12)\n",
    "#     plt.xlabel('Prediction',fontsize=12)\n",
    "#     plt.show()\n",
    "\n",
    "    ### 8. Quadratic Discriminant Analysis\n",
    "#     print(\"=============================================================================================\")   \n",
    "#     print(\"8. Quadratic Discriminant Analysis\")\n",
    "\n",
    "    clf = QuadraticDiscriminantAnalysis(tol=1e-4)\n",
    "    clf.fit(X_train,y_train)\n",
    "    predictions_8 = clf.predict(X_test)\n",
    "\n",
    "    predicted_df = pd.DataFrame(predictions_8, index =X_test.index) \n",
    "    predictions_temp, likelihood_8  = classifier_slice2uid(predicted_df, trigger= trigger) \n",
    "    predictions_8 =  predictions_temp.iloc[:,-1].to_list() \n",
    "    y_test = np.array(phq_score.loc[list(predictions_temp.index),\"dp_class_y\"].to_list()) \n",
    "    mse_8 = np.sum((y_test-list(likelihood_8.values()))**2/len(y_test))\n",
    "\n",
    "#     print(likelihood_8)\n",
    "#     print(\"mse of score by users: \",mse_8)\n",
    "#     print(classification_report(y_test,predictions_8))\n",
    "#     print(\"AC\",accuracy_score(y_test,predictions_8))\n",
    "\n",
    "#     ####################### Plot ############################\n",
    "#     fpr_8, tpr_8, thresholds = \\\n",
    "#     roc_curve(y_test,predictions_8)\n",
    "#     plt.figure(figsize=(10,4))\n",
    "\n",
    "#     plt.subplot(121)\n",
    "#     # plt.xlim(0,1) \n",
    "#     # plt.ylim(0.0,1.1) \n",
    "#     plt.title('ROC',fontsize=14,fontweight='bold')\n",
    "#     plt.xlabel('False Postive Rate')\n",
    "#     plt.ylabel('True Postive Rate')\n",
    "#     plt.plot(fpr_8,tpr_8,linewidth=2, linestyle=\"-\",color='red')\n",
    "\n",
    "#     plt.subplot(122)\n",
    "#     ticks=['Normal','Depression']\n",
    "#     conf_mat = confusion_matrix(y_test, predictions_8)\n",
    "#     sns.heatmap(conf_mat, annot=True, fmt='d',\n",
    "#                 xticklabels=ticks, yticklabels=ticks,cmap=\"Blues\")\n",
    "#     plt.title('Confusion Matrix',fontsize=14,fontweight='bold')\n",
    "#     plt.ylabel('Actual',fontsize=12)\n",
    "#     plt.xlabel('Prediction',fontsize=12)\n",
    "#     plt.show()\n",
    "\n",
    "    ### 9. SVM Classifier \n",
    "#     print(\"=============================================================================================\") \n",
    "#     print(\"9. SVM\")\n",
    "    \n",
    "    clf = SVC(kernel='rbf', probability=True)\n",
    "    clf.fit(X_train,y_train)\n",
    "    predictions_9 = clf.predict(X_test)\n",
    "\n",
    "    predicted_df = pd.DataFrame(predictions_9, index =X_test.index) \n",
    "    predictions_temp, likelihood_9  = classifier_slice2uid(predicted_df, trigger= trigger) \n",
    "    predictions_9 =  predictions_temp.iloc[:,-1].to_list() \n",
    "    y_test = np.array(phq_score.loc[list(predictions_temp.index),\"dp_class_y\"].to_list()) \n",
    "    mse_9 = np.sum((y_test-list(likelihood_9.values()))**2/len(y_test))\n",
    "\n",
    "#     print(likelihood_9)\n",
    "#     print(\"mse of score by users: \",mse_9)\n",
    "#     print(classification_report(y_test,predictions_9))\n",
    "#     print(\"AC\",accuracy_score(y_test,predictions_9))\n",
    "\n",
    "#     ####################### Plot ############################\n",
    "#     fpr_9, tpr_9, thresholds_9 = \\\n",
    "#     roc_curve(y_test,predictions_9)\n",
    "#     plt.figure(figsize=(10,4))\n",
    "\n",
    "#     plt.subplot(121)\n",
    "#     # plt.xlim(0,1) \n",
    "#     # plt.ylim(0.0,1.1) \n",
    "#     plt.title('ROC',fontsize=14,fontweight='bold')\n",
    "#     plt.xlabel('False Postive Rate')\n",
    "#     plt.ylabel('True Postive Rate')\n",
    "#     plt.plot(fpr_9,tpr_9,linewidth=2, linestyle=\"-\",color='red')\n",
    "\n",
    "#     plt.subplot(122)\n",
    "#     ticks=['Normal','Depression']\n",
    "#     conf_mat = confusion_matrix(y_test, predictions_9)\n",
    "#     sns.heatmap(conf_mat, annot=True, fmt='d',\n",
    "#                 xticklabels=ticks, yticklabels=ticks,cmap=\"Blues\")\n",
    "#     plt.title('Confusion Matrix',fontsize=14,fontweight='bold')\n",
    "#     plt.ylabel('Actual',fontsize=12)\n",
    "#     plt.xlabel('Prediction',fontsize=12)\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "    ### 10. knn Classifier \n",
    "#     print(\"=============================================================================================\") \n",
    "#     print(\"10. KNN\")\n",
    "\n",
    "    knn=KNeighborsClassifier(n_neighbors=5)\n",
    "    knn = KNeighborsClassifier()\n",
    "    knn.fit(X_train,y_train)\n",
    "    predictions_10 = knn.predict(X_test)\n",
    "\n",
    "    predicted_df = pd.DataFrame(predictions_10, index =X_test.index) \n",
    "    predictions_temp, likelihood_10  = classifier_slice2uid(predicted_df, trigger= trigger) \n",
    "    predictions_10 =  predictions_temp.iloc[:,-1].to_list() \n",
    "    y_test = np.array(phq_score.loc[list(predictions_temp.index),\"dp_class_y\"].to_list()) \n",
    "    mse_10 = np.sum((y_test-list(likelihood_10.values()))**2/len(y_test))\n",
    "\n",
    "#     print(likelihood_10)\n",
    "#     print(\"mse of score by users: \",mse_10)\n",
    "#     print(classification_report(y_test,predictions_10))\n",
    "#     print(\"AC\",accuracy_score(y_test,predictions_10))\n",
    "\n",
    "#     ####################### Plot ############################\n",
    "#     fpr_10, tpr_10, thresholds_10 = \\\n",
    "#     roc_curve(y_test,predictions_10)\n",
    "#     plt.figure(figsize=(10,4))\n",
    "\n",
    "#     plt.subplot(121)\n",
    "#     # plt.xlim(0,1) \n",
    "#     # plt.ylim(0.0,1.1) \n",
    "#     plt.title('ROC',fontsize=14,fontweight='bold')\n",
    "#     plt.xlabel('False Postive Rate')\n",
    "#     plt.ylabel('True Postive Rate')\n",
    "#     plt.plot(fpr_10,tpr_10,linewidth=2, linestyle=\"-\",color='red')\n",
    "\n",
    "#     plt.subplot(122)\n",
    "#     ticks=['Normal','Depression']\n",
    "#     conf_mat = confusion_matrix(y_test, predictions_10)\n",
    "#     sns.heatmap(conf_mat, annot=True, fmt='d',\n",
    "#                 xticklabels=ticks, yticklabels=ticks,cmap=\"Blues\")\n",
    "#     plt.title('Confusion Matrix',fontsize=14,fontweight='bold')\n",
    "#     plt.ylabel('Actual',fontsize=12)\n",
    "#     plt.xlabel('Prediction',fontsize=12)\n",
    "#     plt.show()\n",
    "\n",
    "    \n",
    "    return likelihood_1,likelihood_2,likelihood_3,likelihood_4,likelihood_5, likelihood_6, likelihood_7, likelihood_8,likelihood_9, likelihood_10,\\\n",
    "    mse_1,mse_2,mse_3,mse_4,mse_5,mse_6,mse_7,mse_8,mse_9,mse_10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53516e93",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage1 prediction result saved in: ../data/\n"
     ]
    }
   ],
   "source": [
    "# ###############  start iteration by augmentation factor ###################\n",
    "# #######################################################################\n",
    "import time\n",
    "seed_value =0 \n",
    "split_rate =0.8\n",
    "\n",
    "## start train and predict\n",
    "p_ml =  pd.DataFrame()\n",
    "# nondepression_idnum_train=len(np.unique(y_train.index))-len(id_dptrain) # none depression id number in training\n",
    "nondepression_idnum_train=len(np.unique(y_train.index))\n",
    "\n",
    "algorithm_list = [\"BLANK\",\"RF\",\"LR\",\"DT\",\"GBDT\",\"AB\",\"GNB\",\"LDA\",\"QDA\",\"SVM\",\"KNN\"]\n",
    "\n",
    "for j in range(6):   # j stands for the augmenting factor \n",
    "    X_train, y_train, X_test, y_test, y_train_dummy, y_test_dummy, id_train, id_test \\\n",
    "    = generate_train_test(dataset_1, agm_factor=j, random_seed = seed_value) # generate train dataset\n",
    "    \n",
    "    score_user_1,score_user_2,score_user_3,score_user_4,score_user_5, score_user_6, score_user_7, score_user_8,\\\n",
    "    score_user_9,score_user_10, mse_1,mse_2,mse_3,mse_4,mse_5,mse_6,mse_7,mse_8,mse_9,mse_10 \\\n",
    "    = ml_predict_score_user(X_train, y_train, X_test, y_test_uid) # train and predict with ML ================\n",
    "    \n",
    "\n",
    "    for i in range(1,len(algorithm_list)): # total 10 algorithms, starts from 1\n",
    "#         print('score_user_{}='.format(i))\n",
    "#         var=eval(\"score_user_\"+str(i))\n",
    "#         print(var)\n",
    "        p_temp=[] \n",
    "        p_temp.append(int(time.time()))\n",
    "        p_temp.append(j)\n",
    "        p_temp.extend(list(eval(\"score_user_\"+str(i)).values()))  # predicted\n",
    "        p_temp.extend(y_test_uid)  # ground truth in user granilarity\n",
    "        p_temp.append(eval(\"mse_\"+str(i)))\n",
    "        p_temp.append(entropy(list(eval(\"score_user_\"+str(i)).values()))) # entropy under prediction with algorithm i\n",
    "        p_temp.append(algorithm_list[i])\n",
    "        p_temp.append(len(col_slct))\n",
    "        p_temp.append(seed_value)\n",
    "        p_series =  pd.Series(p_temp)\n",
    "        p_ml = p_ml.append(p_series, ignore_index=True)\n",
    "\n",
    "user_prob_col, user_gth_col, user_prd_col, =[], [], []\n",
    "[(user_prob_col.append(u+'_prob'), user_gth_col.append(u+'gth'), user_prd_col.append(u+'_prd')) for u in score_user_1.keys()] # e.g. [u01_prd, ...]\n",
    "\n",
    "p_col = [\"time\",\"aug_factor\"]+user_prob_col + user_gth_col +[\"mse\",\"entropy\",\"model\",\"feature num\",\"random seed\"]\n",
    "p_ml.columns= p_col\n",
    "p_ml['feature num']=p_ml['feature num'].astype(int) #format the feature type\n",
    "p_ml['aug_factor']=p_ml['aug_factor'].astype(int)\n",
    "p_ml.to_csv(dir_data+\"likelihood.csv\", mode=\"a\", index= False)\n",
    "print(\"Stage1 prediction result saved in:\", dir_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8a5825",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "B.train and predict by DNN \n",
    "\n",
    "###################### ONLY for DNN experiment to find aug factor: ##############################\n",
    "##############  output: array of factor+ predicted probability list by user_test+ trueth list + mse  ############\n",
    "############### this section follows the function defination sections(before data process section)  ###############\n",
    "\n",
    "'''\n",
    "\n",
    "import time\n",
    "###############  Training ,prediction #################################\n",
    "def dnn_predict_score_user(X_train, y_train_dummy, epochs):\n",
    "    epochs = epochs\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=X_train.shape[1], activation='relu')) # input_dim = numb of features, 1D number\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(2, activation='sigmoid'))  # 5 classes\n",
    "#     model.summary()\n",
    "    # model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.compile(optimizer='adam',loss='mse', metrics=['mae', 'acc']) \n",
    "    history=model.fit(X_train, y_train_dummy, epochs=epochs,validation_split=0.33, batch_size=32, verbose = 0)\n",
    "\n",
    "    y_predict = model.predict(X_test)\n",
    "    y_predicted = y_predict.argmax(axis = 1)\n",
    "    y_t = y_test_dummy.argmax(axis =1)\n",
    "\n",
    "    predicted_df = pd.DataFrame(y_predicted, index =X_test.index) # dataframe of predected label + user index\n",
    "    predictions_temp, score_user  = classifier_slice2uid(predicted_df, trigger= trigger) # predictions output in df formate , by user id\n",
    "    predictions =  predictions_temp.iloc[:,-1].to_list()  # convert to array \n",
    "    y_t = np.array(phq_score.loc[list(predictions_temp.index),\"dp_class_y\"].to_list())  # pickup the associated test's depression label by user\n",
    "    mse = np.sum((y_t-list(score_user.values()))**2/len(y_t))\n",
    "    return score_user, y_t, mse\n",
    "\n",
    "\n",
    "#############  pick up features， see what's picked in ML algorithm portion ###########################\n",
    "\n",
    "\n",
    "# 0. all features\n",
    "col_slct= full_col # ALL features, 78 cols after manully filter \"null\" and \"green\" columns\n",
    "\n",
    "# # 1. EMA 6 + sensing 4\n",
    "col_slct=['Mood_happyornot','PAM_picture_idx', 'Mood_sad','Stress_level','Sleep_social','Sleep_rate',\n",
    "            'dark_duration(sec)','audio_ audio inference',\n",
    "#             'phonecharge_duration(sec)','activity_ activity inference'] \n",
    "\n",
    "# # # 2. EMA  6 features\n",
    "col_slct=['Mood_happyornot','PAM_picture_idx', 'Mood_sad','Stress_level','Sleep_social','Sleep_rate']\n",
    "\n",
    "# # # # 3. sensing 4 features\n",
    "col_slct=['dark_duration(sec)','audio_ audio inference',\n",
    "          'phonecharge_duration(sec)','activity_ activity inference'] \n",
    "\n",
    "''' Data processing 1:\n",
    "    - select columns\n",
    "    - normalization\n",
    "    - PCA (on demand)\n",
    "'''\n",
    "\n",
    "dataset_col = dataset[col_slct]\n",
    "\n",
    "data_norm= minmax_normalize(dataset_col)\n",
    "data_norm=data_norm.fillna(0) # choose -1 or 0\n",
    "\n",
    "## process PCA ############\n",
    "# dataset_np = data_norm.iloc[:,1:].to_numpy()  # transfer to numpy without index of 'user_date'\n",
    "# K=2\n",
    "# dataset_np=PCA(dataset_np, K, axis= 1)\n",
    "# dataset_np.shape\n",
    "# dataset_pca=pd.DataFrame(dataset_np, columns= np.arange(K), index= data_norm.index)\n",
    "\n",
    "\n",
    "# print(\"Below is data_norm:\")\n",
    "# data_norm\n",
    "\n",
    "''' Data processing 2:\n",
    "    - add lables\n",
    "    - clean data\n",
    "    '''\n",
    "\n",
    "\n",
    "########### 1.2 add label(dp_class) by merging phq ###############\n",
    "########## add uer and set as index for merging phq ###########\n",
    "\n",
    "\n",
    "# dataset_1=dataset   # no pca, no normalization\n",
    "dataset_1 = data_norm # with normalization , no pca\n",
    "# dataset_1= dataset_pca # with both normalization + pca\n",
    "\n",
    "dataset_1['user']=dataset_1.index  # copy 'user' column with index values\n",
    "def str_slice(str):\n",
    "    return str[:3]\n",
    "dataset_1['user']=dataset_1['user'].apply(str_slice)\n",
    "dataset_1 = dataset_1.reset_index().set_index('user') \n",
    "dataset_1 = dataset_1.drop(['user_date'], axis=1)# keep the index columns and set 'user' col as index\n",
    "# dataset_1.fillna(0, inplace= True)\n",
    "print(\"Dataset before labeling is:\", dataset_1.shape)\n",
    "\n",
    "## add label of dp_class\n",
    "dp_class_list=[]\n",
    "for user in dataset_1.index: \n",
    "    if user in phq_selected.index.to_list():\n",
    "        dp_class_list.append(phq_selected.loc[user]['dp_class_y'])\n",
    "    else:\n",
    "        dp_class_list.append(None) # for removing those users are not in the selected list\n",
    "dataset_1['dp_class']=dp_class_list\n",
    "\n",
    "dataset_1= dataset_1.dropna() #dataset_1= dataset_1.dropna(how='all')  will cause big issue\n",
    "dataset_1= dataset_1.fillna(0)\n",
    "\n",
    "# dataset_2 = minmax_normalize(dataset_1)\n",
    "print(\"After labeling and removing non-completed label, dataset shape is:\", dataset_1.shape)\n",
    "\n",
    "''' Data processing 3:\n",
    "    - Split training and testing dataset\n",
    "    - Data augment : pick the id with depression ,which stays in train dataset for augmenting'''\n",
    "\n",
    "# process training and testing data ########\n",
    "random.seed(seed_value)  # 0, 42, etc\n",
    "trigger =0.2 # threshold for debugging\n",
    "dataset_full= dataset_1 \n",
    "id_list =list(np.unique(dataset_full.index))\n",
    "split = int(0.8*len(id_list))\n",
    "\n",
    "\n",
    "id_train= sorted(random.sample(id_list,split))\n",
    "id_test= sorted(list(set(id_list)- set(id_train)))\n",
    "id_depression_all=list(np.unique(dataset.where(dataset_1['dp_class'] == 1).dropna().index)) # users who has depression\n",
    "id_dptrain=[]\n",
    "\n",
    "for id in id_depression_all:\n",
    "    if (id in id_train):\n",
    "        id_dptrain.append(id)  #add to augment id list for depression id in train dataset\n",
    "# print(id_dptrain)\n",
    "###############  start iteration ###################\n",
    "import time\n",
    "\n",
    "p_dnn =  pd.DataFrame()\n",
    "# nondepression_idnum_train=len(np.unique(y_train.index))-len(id_dptrain) # none depression id number in training\n",
    "nondepression_idnum_train=len(np.unique(y_train.index))\n",
    "\n",
    "for j in range(nondepression_idnum_train):       \n",
    "    p_temp=[]    \n",
    "    \n",
    "    agm_factor = j # add 4 times depressed user data, randomly        \n",
    "    id_augment = []\n",
    "    for i in range(agm_factor): # add users in train dataset with depression     \n",
    "        id_augment.append(random.sample(id_dptrain,1)[0])\n",
    "\n",
    "    id_agm =id_train+id_augment\n",
    "    random.shuffle(id_agm)\n",
    "\n",
    "    X_train= dataset_1.loc[id_agm,:].iloc[:,:-1] # X_train shape[0] will increase after augmenting\n",
    "    y_train= dataset_1.loc[id_agm,:].iloc[:,-1]\n",
    "#     print(\"id_augment\", id_agm)\n",
    "\n",
    "    X_test= dataset_1.loc[id_test,:].iloc[:,:-1]\n",
    "    y_test= dataset_1.loc[id_test,:].iloc[:,-1]\n",
    "    y_train_dummy = pd.get_dummies(y_train).values\n",
    "    y_test_dummy = pd.get_dummies(y_test).values\n",
    "\n",
    "    score_user, y_t, mse = dnn_predict_score_user(X_train, y_train_dummy, 200) # train and predict with CNN ================\n",
    "    p_temp.append(int(time.time()))\n",
    "    p_temp.append(j)\n",
    "    p_temp.extend(list(score_user.values()))\n",
    "    p_temp.extend(y_t)\n",
    "    p_temp.append(mse)\n",
    "    p_temp.append(entropy(list(score_user.values())))\n",
    "    p_temp.append(\"DNN\")\n",
    "    p_temp.append(len(col_slct))\n",
    "    p_temp.append(seed_value)\n",
    "  \n",
    "    p_series =  pd.Series(p_temp)\n",
    "    p_dnn = p_dnn.append(p_series, ignore_index=True)\n",
    "p_col = [\"time\",\"aug_factor\"]+list(score_user.keys())*2+[\"mse\",\"entropy\",\"model\",\"feature num\",\"random seed\"]\n",
    "p_dnn.columns= p_col\n",
    "p_dnn['feature num']=p_dnn['feature num'].astype(int) #format the feature type\n",
    "p_dnn['aug_factor']=p_dnn['aug_factor'].astype(int)\n",
    "\n",
    "p_dnn.to_csv(dir_data+\"likelihood.csv\", mode=\"a\", index = False)\n",
    "print(\"DNN entropy report saved:\", dir_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4959edbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "''' C.train and predict by CNN\n",
    "\n",
    "###################### ONLY for CNN experiment to find aug factor: ##############################\n",
    "##############  output: array of factor+ predicted probability list by user_test+ trueth list + mse  ############\n",
    "############### this section follows the function defination sections(before data process section)  ###############\n",
    "'''\n",
    "\n",
    "import time\n",
    "###############  Training ,prediction #################################\n",
    "\n",
    "def cnn_predict_score_user(X_train_conv, y_train_conv_dummy,X_test_conv,y_test_conv_dummy,y_test_conv_index, epochs):\n",
    "    input_shape = (X_train_conv.shape[1],X_train_conv.shape[2],X_train_conv.shape[3]) # e.g. shape of (7, 87, 1) \n",
    "    num_classes = 2\n",
    "    batch_size = 32\n",
    "    epochs =epochs\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, kernel_size=(2, 2), input_shape=input_shape, strides=(1, 1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    # model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "    # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "#     model.summary()\n",
    "\n",
    "    model.compile(optimizer='adam',loss='mse', metrics=['mae', 'acc']) \n",
    "    history=model.fit(X_train_conv, y_train_conv_dummy, epochs=epochs,validation_split=0.33, batch_size=batch_size, verbose = 0)\n",
    "    y_predict = model.predict(X_test_conv)\n",
    "    y_predicted = y_predict.argmax(axis = 1)\n",
    "#     y_t = y_test_conv_dummy.argmax(axis =1)  #len of 180\n",
    "\n",
    "#     predicted_df = pd.DataFrame(y_predicted, index =X_test.index) # dataframe of predected label + user index\n",
    "    predicted_df = pd.DataFrame(y_predicted, index =y_test_conv_index) # dataframe of predected label + user index\n",
    "    predictions_temp, score_user  = classifier_slice2uid(predicted_df, trigger= trigger) # predictions output in df formate , by user id, df format with len 7\n",
    "    predictions =  predictions_temp.iloc[:,-1].to_list()  # convert to array \n",
    "    y_t = np.array(phq_score.loc[list(predictions_temp.index),\"dp_class_y\"].to_list())  # pickup the associated test's depression label by user #len of 7\n",
    "    mse = np.sum((y_t-list(score_user.values()))**2/len(y_t))\n",
    "    return score_user, y_t, mse\n",
    "\n",
    "#############  pick up features, what's picked up by ML algorithm portion ###########\n",
    "\n",
    "''' Data processing 1:\n",
    "    - select columns\n",
    "    - normalization\n",
    "    - PCA (on demand)\n",
    "'''\n",
    "\n",
    "# 0. all features\n",
    "col_slct= full_col # ALL features, 78 cols after manully filter \"null\" and \"green\" columns\n",
    "\n",
    "# # 1. EMA 6 + sensing 4\n",
    "col_slct=['Mood_happyornot','PAM_picture_idx', 'Mood_sad','Stress_level','Sleep_social','Sleep_rate',\n",
    "            'dark_duration(sec)','audio_ audio inference',\n",
    "            'phonecharge_duration(sec)','activity_ activity inference'] \n",
    "\n",
    "# # # 2. EMA  6 features\n",
    "col_slct=['Mood_happyornot','PAM_picture_idx', 'Mood_sad','Stress_level','Sleep_social','Sleep_rate']\n",
    "\n",
    "# # # # 3. sensing 4 features\n",
    "col_slct=['dark_duration(sec)','audio_ audio inference',\n",
    "          'phonecharge_duration(sec)','activity_ activity inference'] \n",
    "\n",
    "dataset_col = dataset[col_slct]\n",
    "\n",
    "data_norm= minmax_normalize(dataset_col)\n",
    "data_norm=data_norm.fillna(0) # choose -1 or 0\n",
    "\n",
    "## process PCA ############\n",
    "# dataset_np = data_norm.iloc[:,1:].to_numpy()  # transfer to numpy without index of 'user_date'\n",
    "# K=2\n",
    "# dataset_np=PCA(dataset_np, K, axis= 1)\n",
    "# dataset_np.shape\n",
    "# dataset_pca=pd.DataFrame(dataset_np, columns= np.arange(K), index= data_norm.index)\n",
    "\n",
    "\n",
    "# print(\"Below is data_norm:\")\n",
    "# data_norm\n",
    "\n",
    "''' Data processing 2:\n",
    "    - add lables\n",
    "    - clean data\n",
    "    '''\n",
    "########### 1.2 add label(dp_class) by merging phq ###############\n",
    "########## add uer and set as index for merging phq ###########\n",
    "\n",
    "\n",
    "# dataset_1=dataset   # no pca, no normalization\n",
    "dataset_1 = data_norm # with normalization , no pca\n",
    "# dataset_1= dataset_pca # with both normalization + pca\n",
    "\n",
    "dataset_1['user']=dataset_1.index  # copy 'user' column with index values\n",
    "def str_slice(str):\n",
    "    return str[:3]\n",
    "dataset_1['user']=dataset_1['user'].apply(str_slice)\n",
    "dataset_1 = dataset_1.reset_index().set_index('user') \n",
    "dataset_1 = dataset_1.drop(['user_date'], axis=1)# keep the index columns and set 'user' col as index\n",
    "# dataset_1.fillna(0, inplace= True)\n",
    "print(\"Dataset before labeling is:\", dataset_1.shape)\n",
    "\n",
    "## add label of dp_class\n",
    "dp_class_list=[]\n",
    "for user in dataset_1.index: \n",
    "    if user in phq_selected.index.to_list():\n",
    "        dp_class_list.append(phq_selected.loc[user]['dp_class_y'])\n",
    "    else:\n",
    "        dp_class_list.append(None) # for removing those users are not in the selected list\n",
    "dataset_1['dp_class']=dp_class_list\n",
    "\n",
    "dataset_1= dataset_1.dropna() #dataset_1= dataset_1.dropna(how='all')  will cause big issue\n",
    "dataset_1= dataset_1.fillna(0)\n",
    "\n",
    "# dataset_2 = minmax_normalize(dataset_1)\n",
    "print(\"After labeling and removing non-completed label, dataset shape is:\", dataset_1.shape)\n",
    "\n",
    "''' Data processing 3:\n",
    "    - Split training and testing dataset\n",
    "    - Data augment : pick the id with depression ,which stays in train dataset for augmenting'''\n",
    "\n",
    "# process training and testing data ########\n",
    "random.seed(seed_value)  # 1 depression : 0, 42, etc\n",
    "trigger =0.2 # for debugging only\n",
    "dataset_full= dataset_1 \n",
    "id_list =list(np.unique(dataset_full.index))\n",
    "split = int(0.8*len(id_list))\n",
    "\n",
    "\n",
    "id_train= sorted(random.sample(id_list,split))\n",
    "id_test= sorted(list(set(id_list)- set(id_train)))\n",
    "\n",
    "id_dptrain=[]\n",
    "id_depression_all=list(np.unique(dataset.where(dataset_1['dp_class'] == 1).dropna().index)) # users who has depression\n",
    "for id in id_depression_all:\n",
    "    if (id in id_train):\n",
    "        id_dptrain.append(id)  #add to augment id list for depression id in train dataset\n",
    "\n",
    "###############  start iteration ###################\n",
    "import time\n",
    "\n",
    "p_cnn =  pd.DataFrame()\n",
    "# nondepression_idnum_train=len(np.unique(y_train.index))-len(id_dptrain) # none depression id number in training\n",
    "nondepression_idnum_train=len(np.unique(y_train.index))\n",
    "\n",
    "for j in range(nondepression_idnum_train):       \n",
    "    p_temp=[]    \n",
    "    \n",
    "    agm_factor = j # add 4 times depressed user data, randomly        \n",
    "    id_augment = []\n",
    "    for i in range(agm_factor): # add users in train dataset with depression     \n",
    "        id_augment.append(random.sample(id_dptrain,1)[0])\n",
    "\n",
    "    id_agm =id_train+id_augment\n",
    "    random.shuffle(id_agm)\n",
    "\n",
    "    X_train= dataset_1.loc[id_agm,:].iloc[:,:-1] # X_train shape[0] will increase after augmenting\n",
    "    y_train= dataset_1.loc[id_agm,:].iloc[:,-1]\n",
    "    X_test= dataset_1.loc[id_test,:].iloc[:,:-1]\n",
    "    y_test= dataset_1.loc[id_test,:].iloc[:,-1]\n",
    "    y_train_dummy = pd.get_dummies(y_train).values\n",
    "    y_test_dummy = pd.get_dummies(y_test).values\n",
    "    \n",
    "    \n",
    "   ################### BELOW ONLY FOR CNN training dataset splitting ####################\n",
    "    '''reshape the 2d dataset to 4d, chop the label, to fit CNN'''\n",
    "\n",
    "\n",
    "    step = 3 # no lower than 3 ,cause the CNN kernel size is (2,2),7 is the best,\n",
    "\n",
    "    X_temp=np.array(X_train.iloc[:X_train.shape[0]-(X_train.shape[0]%step),:]) # through off the last few rows un-reshapable\n",
    "    X_train_conv = np.expand_dims(X_temp.reshape(int(X_temp.shape[0]/step), step, X_temp.shape[1]), axis=3) # e.g. from (3010, 87) to (430, 7, 87, 1)\n",
    "    X_temp=np.array(X_test.iloc[:X_test.shape[0]-(X_test.shape[0]%step),:]) \n",
    "    X_test_conv = np.expand_dims(X_temp.reshape(int(X_temp.shape[0]/step), step, X_temp.shape[1]), axis=3)\n",
    "\n",
    "    y_temp=np.array(y_train.iloc[:y_train.shape[0]-(y_train.shape[0]%step),]) \n",
    "    y_temp = y_temp.reshape(int(y_temp.shape[0]/step), step)\n",
    "    y_train_conv = np.mean(y_temp, axis=1)\n",
    "    for i in range(y_train_conv.shape[0]): y_train_conv[i]=round(y_train_conv[i])\n",
    "\n",
    "    y_temp=np.array(y_test.iloc[:y_test.shape[0]-(y_test.shape[0]%step),]) \n",
    "    y_temp = y_temp.reshape(int(y_temp.shape[0]/step), step)\n",
    "    y_test_conv = np.mean(y_temp, axis=1)\n",
    "    for i in range(y_test_conv.shape[0]): y_test_conv[i]=round(y_test_conv[i])\n",
    "\n",
    "    y_train_conv_dummy = pd.get_dummies(y_train_conv).values\n",
    "    y_test_conv_dummy = pd.get_dummies(y_test_conv).values\n",
    "\n",
    "    ########## transfer y_label from one day slice to step(e.g. 7)) days slice, use majority rule  ############\n",
    "    y_test_index= y_test.index\n",
    "    y_test_index = y_test_index[:-(len(y_test_index)%step)]\n",
    "    y_test_conv_index =[]\n",
    "    for i in range(0,len(y_test_index), step):\n",
    "        user_slice = list(y_test_index[i:i+step])\n",
    "        user_id = np.unique(user_slice)\n",
    "        if len(user_id ) <= 1: \n",
    "            y_test_conv_index.append(user_id[0])\n",
    "        else:   # if there are more than 1 user id in the sliced user id, select the majority\n",
    "            if user_slice.count(user_slice[0]) > user_slice.count(user_slice[-1]): \n",
    "                y_test_conv_index.append(user_slice[0])\n",
    "            else: y_test_conv_index.append(user_slice[-1])\n",
    "            \n",
    "######################## above only for CNN ###########\n",
    "    \n",
    "   \n",
    "    score_user, y_t, mse = cnn_predict_score_user(X_train_conv, y_train_conv_dummy,X_test_conv,y_test_conv_dummy,y_test_conv_index, 200) # train and predict with CNN ================\n",
    "    p_temp.append(int(time.time()))\n",
    "    p_temp.append(j)\n",
    "    p_temp.extend(list(score_user.values()))\n",
    "    p_temp.extend(y_t)\n",
    "    p_temp.append(mse)\n",
    "    p_temp.append(entropy(list(score_user.values())))\n",
    "    p_temp.append(\"CNN\")\n",
    "    p_temp.append(len(col_slct))\n",
    "    p_temp.append(seed_value)\n",
    "#     print(\"score by user\", score_user)\n",
    "#     print(\"yt\",y_t)\n",
    "#     print(\"mse\",mse)\n",
    "    \n",
    "    p_series =  pd.Series(p_temp)\n",
    "    p_cnn = p_cnn.append(p_series, ignore_index=True)\n",
    "p_col = [\"time\",\"aug_factor\"]+list(score_user.keys())*2+[\"mse\",\"entropy\",\"model\",\"feature num\",\"random seed\"]\n",
    "p_cnn.columns= p_col\n",
    "p_cnn['feature num']=p_cnn['feature num'].astype(int) #format the feature type\n",
    "p_cnn['aug_factor']=p_cnn['aug_factor'].astype(int)\n",
    "p_cnn.to_csv(dir_data+\"likelihood.csv\", mode=\"a\")\n",
    "\n",
    "print(\"CNN  entropy report saved:\", dir_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6201f89",
   "metadata": {},
   "source": [
    "## Prediction stage-2\n",
    "    - predict with probability lists by using student_t\n",
    "    - store the result to file: dir_data+\"final_result.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b5a5e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prob_col = ['u00_prob', 'u07_prob',  'u10_prob',  'u17_prob', 'u34_prob',  'u35_prob',  'u47_prob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11413af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['u00_prd', 'u07_prd', 'u10_prd', 'u17_prd', 'u34_prd', 'u35_prd', 'u47_prd']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prd_col =['u00_prd', 'u07_prd', 'u10_prd', 'u17_prd', 'u34_prd', 'u35_prd', 'u47_prd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4bede9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final result save in: ../data/ final_result.csv.\n"
     ]
    }
   ],
   "source": [
    "## predict with probability lists by using student_t\n",
    "import pandas as pd\n",
    "dir_data = '../data/'\n",
    "\n",
    "# STUDENT-t\n",
    "def student_t(data):\n",
    "    n=len(data)\n",
    "    mu= np.mean(data)\n",
    "    S= np.std(data,ddof=1)#variance\n",
    "    t_av= 1.440 #https:// 90% confidence, 1 side, en.wikipedia.org/wiki/Student%27s_t-distribution\n",
    "#     t_av =0.906 # 80%\n",
    "    t_av= 1.943 #  95% confidentce, 1 side\n",
    "    X_left = mu-t_av*S/np.sqrt(n)\n",
    "    X_right = mu +t_av*S/np.sqrt(n)\n",
    "#     print(X_left,\",\",X_right)\n",
    "    result=[]\n",
    "    for i in range(len(data)):\n",
    "        if data[i] >= X_right:\n",
    "            result.append(1)\n",
    "        else:\n",
    "            result.append(0)\n",
    "    return result\n",
    "\n",
    "data_result = pd.read_csv(dir_data+'likelihood.csv')\n",
    "data_prd =pd.DataFrame(columns = user_prd_col, dtype=object) # seed= 0： user_prd_col =['u00_prd', 'u07_prd', 'u10_prd', 'u17_prd', 'u34_prd', 'u35_prd', 'u47_prd']\n",
    "\n",
    "for i in range(len(data_result.index)):\n",
    "    prd_stage2 =  student_t(data_result[user_prob_col].iloc[i,:])  # when seed = 0, user_prob_col = ['u00_prob', 'u07_prob',  'u10_prob',  'u17_prob', 'u34_prob',  'u35_prob',  'u47_prob']\n",
    "    data_prd.loc[len(data_prd.index)] = prd_stage2 # add prediction to the row end of dataframe\n",
    "\n",
    "result= pd.merge(data_result, data_prd, left_index=True, right_index= True)\n",
    "result.to_csv(dir_data+\"final_result.csv\", mode=\"w\", index= False)\n",
    "print('Final result save in:', dir_data,\"final_result.csv.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446fbf8e",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Evaluate and plot\n",
    "    - accuracy, recall, precision, f1, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9f64e093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x309.6 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import cm\n",
    "import matplotlib.patches as mpatches\n",
    "dir_data = '../data/' # home win10\n",
    "\n",
    "def normfun(x, mu, sigma):    \n",
    "    pdf = np.exp(-((x - mu)**2)/(2*sigma**2)) / (sigma * np.sqrt(2*np.pi))\n",
    "    return pdf\n",
    "\n",
    "def list_normalize(list): \n",
    "    return (list-min(list))/(max(list)-min(list))\n",
    "\n",
    "file = \"likelihood.csv\"\n",
    "data= pd.read_csv(dir_data+ file)\n",
    "data= data[data[\"feature num\"]== \"10\"] # select EMA+ feature\n",
    "cols=['aug_factor','u00','u07','u10','u17','u34','u35','u47'] # when random seed =0\n",
    "data =data.loc[:,cols]\n",
    "data=data.astype(float) #consider the original data maybe in string formate, transform it to float format\n",
    "data[\"aug_factor\"]=data[\"aug_factor\"].astype(int)\n",
    "#  line style and color: https://matplotlib.org/2.1.2/api/_as_gen/matplotlib.pyplot.plot.html\n",
    "\n",
    "\n",
    "marker_list =[ '*','+', 'o',  's', 'd', 'x', '^', 'v', '<', '>','.','p', 'h']\n",
    "linestyle_list=['-',':','-.','--',':','-.','--',':','-.','--',':','-.']\n",
    "color_list=['k','r','b','g','c','m','y','k','c','g']\n",
    "\n",
    "plt.figure(figsize=(7,4.3))\n",
    "factor_max = 5\n",
    "for i in range(factor_max+1):\n",
    "    d = data[data[\"aug_factor\"]== i].iloc[:,1:]  # densities of all 12 AI models (shape of 12*7), column of \"1:\" means take out the factor number, if in str, transfer i to str\n",
    "    result = list_normalize(d.to_numpy().flatten()) # with normalization all posibilities of 12 AI models, 84\n",
    "#     result =d.to_numpy().flatten() # without normalization\n",
    "    x = np.arange(min(result), max(result), 0.1) #change granularity by change 0.1 to 0.01\n",
    "    y = normfun(x, result.mean(), result.std())\n",
    "    plt.plot(x,y, 'k-', linestyle= linestyle_list[i], color= color_list[i],marker=marker_list[i], \\\n",
    "             mfc=\"None\", label=\"factor \"+str(i), markersize = 7)  # for color\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "# plt.yticks([])\n",
    "\n",
    "\n",
    "### for scalling y-axis to 100%\n",
    "def to_percent(temp, position):\n",
    "    return '%1.0f'%(100*temp) + '%'\n",
    "\n",
    "# plt.xlabel('ratio of days on which a participant is classified as depressed',fontsize=14)\n",
    "plt.xlabel('x',fontsize=18)\n",
    "plt.ylabel('Density:  f(x)', fontsize=14)\n",
    "plt.legend(fontsize=14, loc='upper right')\n",
    "plt.savefig(dir_data+'density_aug_color.pdf',format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fc97ada5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "filename='../data/studentlife_result_byMetricsModelFactor_EMAplusSENSING.csv'\n",
    "data = pd.read_csv(filename)\n",
    "\n",
    "\n",
    "acc_data = data.where(data['metrics']=='A').dropna()\n",
    "\n",
    "list_vanilla = acc_data.where(acc_data['factor']=='vanilla')[['value', 'model']].dropna()\n",
    "list_fct1 = acc_data.where(acc_data['factor']=='1')[['value', 'model']].dropna()\n",
    "list_fct1\n",
    "models= model_order = ['LR','SVM','kNN','DT','GBDT','AB','RF','GNB','LDA','QDA','DNN']\n",
    "\n",
    "l_fct1=list_fct1['value'].tolist()[:-1]\n",
    "l_vanilla = list_vanilla['value'].tolist()\n",
    "l_len = len(l_fct1)\n",
    "\n",
    "plt.show()\n",
    "plt.figure(figsize =(6,2))\n",
    "bar_width = 0.3\n",
    "position_vanilla = np.arange(l_len)\n",
    "position_fct1 = np.arange(l_len)+bar_width\n",
    "plt.bar(position_vanilla, height = l_vanilla, width=bar_width, color = 'skyblue', label = 'Vanilla')\n",
    "plt.bar(position_fct1, height =l_fct1, width= bar_width, color ='olivedrab', label = 'BoostAI')\n",
    "\n",
    "plt.legend(loc= 4) #upper left\n",
    "plt.xticks(position_fct1+bar_width/2, models)\n",
    "plt.ylabel('Accuracy', fontsize= 12)\n",
    "# plt.title ('Accuracy comparison', fontsize=12)\n",
    "\n",
    "dir_data = '../data/' \n",
    "plt.savefig(dir_data+'acc_comp.pdf',format='pdf')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
